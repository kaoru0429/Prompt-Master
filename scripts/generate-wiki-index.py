#!/usr/bin/env python3
"""
Wiki ç´¢å¼•ç”Ÿæˆå™¨
è‡ªå‹•æƒæå°ˆæ¡ˆåŸå§‹ç¢¼ï¼Œç”Ÿæˆå‡½å¼ç´¢å¼•å’Œåƒè€ƒæ–‡æª”
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime

class WikiIndexGenerator:
    def __init__(self, project_root: Path, verbose: bool = False):
        self.project_root = project_root
        self.verbose = verbose
        self.src_dir = project_root / "src"
        self.lib_dir = project_root / "lib"
        self.wiki_dir = project_root / "wiki"

        # ç¢ºä¿ wiki ç›®éŒ„å­˜åœ¨
        self.wiki_dir.mkdir(exist_ok=True)

    def generate(self):
        """ç”Ÿæˆå®Œæ•´çš„ Wiki ç´¢å¼•"""
        print("ğŸ” é–‹å§‹æƒæå°ˆæ¡ˆ...")

        # æƒæå‡½å¼ã€é¡åˆ¥å’Œ API
        functions = self._scan_functions()
        classes = self._scan_classes()
        apis = self._scan_apis()

        # ç”Ÿæˆ JSON ç´¢å¼•
        index_data = {
            "generated_at": datetime.now().isoformat(),
            "version": "1.0",
            "functions": functions,
            "classes": classes,
            "apis": apis,
            "statistics": {
                "total_functions": len(functions),
                "total_classes": len(classes),
                "total_apis": len(apis)
            }
        }

        # å„²å­˜ JSON ç´¢å¼•
        index_file = self.wiki_dir / "index.json"
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… å·²ç”Ÿæˆ JSON ç´¢å¼•: {index_file}")

        # ç”Ÿæˆ Markdown åƒè€ƒæ–‡æª”
        self._generate_function_reference(functions)
        self._generate_api_reference(apis)

        print(f"\nğŸ“Š çµ±è¨ˆ:")
        print(f"   - å‡½å¼: {len(functions)}")
        print(f"   - é¡åˆ¥: {len(classes)}")
        print(f"   - APIs: {len(apis)}")

    def _scan_functions(self) -> List[Dict]:
        """æƒææ‰€æœ‰å‡½å¼"""
        functions = []

        for dir_path in [self.src_dir, self.lib_dir]:
            if not dir_path.exists():
                continue

            for file_path in dir_path.rglob("*.ts"):
                functions.extend(self._extract_functions_from_file(file_path))

            for file_path in dir_path.rglob("*.tsx"):
                functions.extend(self._extract_functions_from_file(file_path))

        return functions

    def _extract_functions_from_file(self, file_path: Path) -> List[Dict]:
        """å¾æª”æ¡ˆä¸­æå–å‡½å¼"""
        functions = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')

            # TypeScript å‡½å¼æ¨¡å¼
            patterns = [
                r'export\s+(?:async\s+)?function\s+(\w+)',  # export function
                r'(?:export\s+)?const\s+(\w+)\s*=\s*(?:async\s+)?\(',  # const func =
                r'(?:public|private|protected)\s+(?:async\s+)?(\w+)\s*\(',  # class methods
            ]

            for line_num, line in enumerate(lines, start=1):
                for pattern in patterns:
                    match = re.search(pattern, line)
                    if match:
                        func_name = match.group(1)

                        # æå–æ–‡æª”è¨»è§£
                        doc_comment = self._extract_doc_comment(lines, line_num - 1)

                        functions.append({
                            "name": func_name,
                            "file": str(file_path.relative_to(self.project_root)),
                            "line": line_num,
                            "file_type": file_path.suffix[1:],
                            "description": doc_comment,
                            "context": line.strip()
                        })

                        if self.verbose:
                            print(f"   æ‰¾åˆ°å‡½å¼: {func_name} @ {file_path.name}:{line_num}")

        except Exception as e:
            print(f"âš ï¸  è®€å–æª”æ¡ˆéŒ¯èª¤ {file_path}: {e}")

        return functions

    def _extract_doc_comment(self, lines: List[str], line_num: int) -> str:
        """æå–æ–‡æª”è¨»è§£"""
        doc_lines = []

        # å‘ä¸Šæœå°‹è¨»è§£
        for i in range(line_num - 1, max(0, line_num - 10), -1):
            line = lines[i].strip()

            if line.startswith('*') or line.startswith('//'):
                doc_lines.insert(0, line.lstrip('/*').strip())
            elif line.startswith('/**'):
                doc_lines.insert(0, line.lstrip('/**').strip())
                break
            elif line and not line.startswith('*'):
                break

        return ' '.join(doc_lines) if doc_lines else ""

    def _scan_classes(self) -> List[Dict]:
        """æƒææ‰€æœ‰é¡åˆ¥"""
        classes = []

        for dir_path in [self.src_dir, self.lib_dir]:
            if not dir_path.exists():
                continue

            for file_path in dir_path.rglob("*.ts"):
                classes.extend(self._extract_classes_from_file(file_path))

        return classes

    def _extract_classes_from_file(self, file_path: Path) -> List[Dict]:
        """å¾æª”æ¡ˆä¸­æå–é¡åˆ¥"""
        classes = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')

            # TypeScript é¡åˆ¥æ¨¡å¼
            pattern = r'(?:export\s+)?class\s+(\w+)'

            for line_num, line in enumerate(lines, start=1):
                match = re.search(pattern, line)
                if match:
                    class_name = match.group(1)

                    doc_comment = self._extract_doc_comment(lines, line_num - 1)

                    classes.append({
                        "name": class_name,
                        "file": str(file_path.relative_to(self.project_root)),
                        "line": line_num,
                        "file_type": file_path.suffix[1:],
                        "description": doc_comment,
                        "context": line.strip()
                    })

                    if self.verbose:
                        print(f"   æ‰¾åˆ°é¡åˆ¥: {class_name} @ {file_path.name}:{line_num}")

        except Exception as e:
            print(f"âš ï¸  è®€å–æª”æ¡ˆéŒ¯èª¤ {file_path}: {e}")

        return classes

    def _scan_apis(self) -> List[Dict]:
        """æƒæ API ç«¯é»"""
        # TODO: å¯¦ä½œ API ç«¯é»æƒæ
        # éœ€è¦æ ¹æ“šå¯¦éš›çš„è·¯ç”±å®šç¾©æ–¹å¼ä¾†å¯¦ä½œ
        return []

    def _generate_function_reference(self, functions: List[Dict]):
        """ç”Ÿæˆå‡½å¼åƒè€ƒæ–‡æª”"""
        output_file = self.wiki_dir / "function-reference.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# å‡½å¼åƒè€ƒ (Function Reference)\n\n")
            f.write(f"> è‡ªå‹•ç”Ÿæˆæ–¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**å‡½å¼ç¸½æ•¸**: {len(functions)}\n\n")
            f.write("---\n\n")

            # ä¾æª”æ¡ˆåˆ†çµ„
            functions_by_file = {}
            for func in functions:
                file_path = func["file"]
                if file_path not in functions_by_file:
                    functions_by_file[file_path] = []
                functions_by_file[file_path].append(func)

            # è¼¸å‡ºæ¯å€‹æª”æ¡ˆçš„å‡½å¼
            for file_path in sorted(functions_by_file.keys()):
                f.write(f"## ğŸ“ {file_path}\n\n")

                for func in functions_by_file[file_path]:
                    f.write(f"### `{func['name']}`\n\n")
                    f.write(f"**ä½ç½®**: {func['file']}:{func['line']}\n\n")

                    if func['description']:
                        f.write(f"**èªªæ˜**: {func['description']}\n\n")

                    f.write(f"```typescript\n{func['context']}\n```\n\n")
                    f.write("---\n\n")

        print(f"âœ… å·²ç”Ÿæˆå‡½å¼åƒè€ƒ: {output_file}")

    def _generate_api_reference(self, apis: List[Dict]):
        """ç”Ÿæˆ API åƒè€ƒæ–‡æª”"""
        output_file = self.wiki_dir / "api-reference.md"

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# API åƒè€ƒ (API Reference)\n\n")
            f.write(f"> è‡ªå‹•ç”Ÿæˆæ–¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**API ç«¯é»ç¸½æ•¸**: {len(apis)}\n\n")
            f.write("---\n\n")

            if not apis:
                f.write("âš ï¸ å°šæœªå®šç¾© API ç«¯é»\n")
            else:
                for api in apis:
                    f.write(f"## `{api['method']} {api['path']}`\n\n")
                    f.write(f"**èªªæ˜**: {api['description']}\n\n")
                    f.write("---\n\n")

        print(f"âœ… å·²ç”Ÿæˆ API åƒè€ƒ: {output_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Wiki ç´¢å¼•ç”Ÿæˆå™¨")
    parser.add_argument("--verbose", "-v", action="store_true", help="é¡¯ç¤ºè©³ç´°è³‡è¨Š")

    args = parser.parse_args()

    # å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„
    project_root = Path(__file__).parent.parent

    # å»ºç«‹ç”Ÿæˆå™¨
    generator = WikiIndexGenerator(project_root, verbose=args.verbose)

    # ç”Ÿæˆç´¢å¼•
    generator.generate()


if __name__ == "__main__":
    main()
